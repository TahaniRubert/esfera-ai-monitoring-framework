{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI Usage & Performance Analysis – Esfera System\n\nEnd-to-end analysis of usage, quality, and operational metrics of an internal AI assistant.","metadata":{}},{"cell_type":"markdown","source":"## 1. Business Context\n\nEsfera is a construction management software that includes a conversational AI assistant.\n\nUsers interact with the AI to:\n- Retrieve project information\n- Interpret operational data\n- Generate summaries\n\nAt this stage, the platform has a small number of active clients, and part of the usage data corresponds to internal testing and training sessions.\n\nGiven this early context, the goal of this analysis is not to measure business impact at scale, but to **understand initial usage behavior, response quality, system stability, and cost dynamics** of the AI feature.\n\nThis exploration aims to provide a structured baseline that can **support future monitoring and decision-making as adoption grows.**\n\nEsfera operates in a **Spanish-speaking market**, and all user interactions analyzed in this project are in Spanish.","metadata":{}},{"cell_type":"markdown","source":"## 2. Objectives\n\nThe objectives of this analysis are:\n\n1. Understand how users interact with the AI within the platform\n2.\tEvaluate how effectively the AI resolves user queries\n3.\tIdentify friction patterns vs. legitimate exploratory usage\n4.\tDefine clear and defensible KPIs for AI performance\n5.\tBuild a structured dataset ready for dashboarding and ongoing monitoring","metadata":{}},{"cell_type":"markdown","source":"## 3. Data Sources\n\nThis analysis is based on two main data views extracted from the Esfera platform.\n\n### 3.1 AI Interaction Logs\n\nThe primary dataset contains conversational interaction logs between users and the AI assistant.  \nMain fields used:\n\n- `UserId`\n- `idEmpresa`\n- `event_ts`\n- `message`\n- `response`\n- `Error`\n\nThis dataset captures when users interact with the AI, what they ask, and whether the system returns an explicit technical error.\n\n\n### 3.2 AI Performance & Token Metrics\n\nA second data view was incorporated to analyze technical performance and operational cost.  \nKey fields include:\n\n- `duration_ms` (total response time in milliseconds)\n- `ttft` (time to first token, in milliseconds)\n- `prompt_token_count`\n- `candidates_token_count`\n- Derived cost per query (based on token usage)\n\n\n### Data Considerations & Limitations\n\n- There is no structured user satisfaction field.\n- Query types are not pre-classified.\n- Early usage includes internal testing and training activity.\n- Some KPIs (e.g., satisfaction proxy, cost per query) were engineered during the analysis process rather than directly extracted.\n\nAll performance and behavioral metrics presented in this notebook are derived from these structured logs.","metadata":{}},{"cell_type":"markdown","source":"## 4. Methodological Decisions\n\nBefore calculating KPIs, several structural decisions were made to ensure consistent and defensible metrics.\n\n### Session Definition\n\nA session is defined as consecutive interactions from the same user separated by less than 10 minutes.  \nIf the time gap exceeds 10 minutes, a new session begins.\n\nThis allows analysis at session-level instead of isolated messages.\n\n### Real Query Definition\n\nNot all messages represent meaningful analytical intent.\n\nA real query is defined as a message that:\n- Has 20 or more characters, or\n- Contains a question mark (\"?\")\n\nThis filtering removes greetings, trivial messages, and noise without excluding short but intentional queries.\n\n### Proxy-Based Satisfaction\n\nSince there is no explicit user satisfaction field, satisfaction is approximated using behavioral signals.\n\nA session is considered successfully resolved when:\n- It contains 1–2 real queries, and\n- No explicit system error is present.\n\n### Performance & Cost Metrics\n\nUnlike the initial dataset exploration phase, the final analysis includes:\n\n- Response time metrics (average duration in seconds)\n- Time to first token (TTFT)\n- Estimated cost per query based on token usage\n\nThese metrics were derived from the enriched logs view containing token and timing information.","metadata":{}},{"cell_type":"markdown","source":"## 5. Exploratory Analysis: Types of AI Queries\n\nThe goal of this section is to understand what users primarily use the AI for inside the Esfera system.\n\nRather than focusing on performance metrics, this analysis provides **contextual insight into user intent and usage patterns.**\n\n\n### 5.1 Query Classification Approach\n\nSince there is no structured field indicating the type of query, a keyword-based classification was implemented.\n\nEach message was evaluated using heuristic rules based on recurring terms such as:\n\n- **Financial terms** (cost, budget, supplier, inventory)\n- **Project progress** terms (progress, advancement, status)\n- **Reporting terms** (summary, report, chart/graph)\n- **System guidance questions** (how to use, modules, features/functions)\n- **Planning-related terms** (schedule, deadline, date)\n- **Operational actions** (enter, edit, modify)\n- **Support requests** (support, agent/representative)\n\nEach message can activate one or more thematic flags depending on detected keywords.\n\nThis classification is exploratory and descriptive, not a production-level NLP model.\n\n***Note:*** The original user messages are written in Spanish, as **Esfera operates in a Spanish-speaking business** environment. \n\nTherefore, keyword-based classification rules are also defined in Spanish to ensure semantic consistency with the source data.","metadata":{}},{"cell_type":"markdown","source":"### 5.2 SQL Used to Calculate Distribution\n\nThe following BigQuery SQL was used to classify queries and compute their distribution by topic.\n\nNote: This query was **executed in Google BigQuery**. It is shown here for documentation purposes.","metadata":{}},{"cell_type":"markdown","source":"```sql\nWITH base AS (\n  SELECT\n    IF(LOWER(message) LIKE '%en que proyecto%' OR LOWER(message) LIKE '%que proyecto%' OR\n       LOWER(message) LIKE '%modulos%' OR LOWER(message) LIKE '%funciones%' OR\n       LOWER(message) LIKE '%que puedo consultar%' OR LOWER(message) LIKE '%como funciona%' OR\n       LOWER(message) LIKE '%como usar%', 1, 0) AS dim_orientacion,\n\n    IF(LOWER(message) LIKE '%avance%' OR LOWER(message) LIKE '%progreso%' OR\n       LOWER(message) LIKE '%como vamos%' OR LOWER(message) LIKE '%estado%', 1, 0) AS dim_avance,\n\n    IF(LOWER(message) LIKE '%presupuesto%' OR LOWER(message) LIKE '%costo%' OR\n       LOWER(message) LIKE '%gasto%' OR LOWER(message) LIKE '%material%' OR\n       LOWER(message) LIKE '%proveedor%' OR LOWER(message) LIKE '%pago%' OR\n       LOWER(message) LIKE '%stock%' OR LOWER(message) LIKE '%inventario%' OR\n       LOWER(message) LIKE '%item mas caro%' OR LOWER(message) LIKE '%item mas barato%', 1, 0) AS dim_finanzas,\n\n    IF(LOWER(message) LIKE '%cronograma%' OR LOWER(message) LIKE '%plazo%' OR\n       LOWER(message) LIKE '%fecha%' OR LOWER(message) LIKE '%cuando%', 1, 0) AS dim_planificacion,\n\n    IF(LOWER(message) LIKE '%ingresar%' OR LOWER(message) LIKE '%cargar%' OR\n       LOWER(message) LIKE '%editar%' OR LOWER(message) LIKE '%modificar%', 1, 0) AS dim_operacion,\n\n    IF(LOWER(message) LIKE '%resum%' OR LOWER(message) LIKE '%reporte%' OR\n       LOWER(message) LIKE '%grafico%' OR LOWER(message) LIKE '%dashboard%', 1, 0) AS dim_reportes,\n\n    IF(LOWER(message) LIKE '%hablar con%' OR LOWER(message) LIKE '%soporte%' OR\n       LOWER(message) LIKE '%agente%', 1, 0) AS dim_soporte\n\n  FROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_producto_vw`\n  WHERE message IS NOT NULL\n),\n\ntotales AS (\n  SELECT\n    SUM(dim_orientacion) AS orientacion,\n    SUM(dim_avance) AS avance,\n    SUM(dim_finanzas) AS finanzas,\n    SUM(dim_planificacion) AS planificacion,\n    SUM(dim_operacion) AS operacion,\n    SUM(dim_reportes) AS reportes,\n    SUM(dim_soporte) AS soporte\n  FROM base\n),\n\ntotal_general AS (\n  SELECT\n    orientacion + avance + finanzas + planificacion + operacion + reportes + soporte AS total\n  FROM totales\n)\n\nSELECT\n  'Orientación' AS dimension,\n  ROUND(100 * orientacion / total, 1) AS pct_tema\nFROM totales, total_general\n\nUNION ALL\nSELECT 'Avance', ROUND(100 * avance / total, 1) FROM totales, total_general\nUNION ALL\nSELECT 'Finanzas', ROUND(100 * finanzas / total, 1) FROM totales, total_general\nUNION ALL\nSELECT 'Planificación', ROUND(100 * planificacion / total, 1) FROM totales, total_general\nUNION ALL\nSELECT 'Operación', ROUND(100 * operacion / total, 1) FROM totales, total_general\nUNION ALL\nSELECT 'Reportes', ROUND(100 * reportes / total, 1) FROM totales, total_general\nUNION ALL\nSELECT 'Soporte', ROUND(100 * soporte / total, 1) FROM totales, total_general;\n```","metadata":{}},{"cell_type":"markdown","source":"### 5.3 Distribution of Queries by Topic\n\nAfter applying the classification logic, the distribution of queries by topic was calculated as follows:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Data\ndata = {\n    \"Query Type\": [\n        \"Finance\",\n        \"Project Progress\",\n        \"Reporting\",\n        \"System Guidance\",\n        \"Planning\",\n        \"Operations\",\n        \"Support\"\n    ],\n    \"Percentage\": [31.3, 30.8, 28.2, 6.2, 1.5, 1.5, 0.5]\n}\n\ndf = pd.DataFrame(data)\n\n# Sort from highest to lowest\ndf = df.sort_values(\"Percentage\", ascending=True)\n\n# Professional color palette (more neutral)\ncolors = [\n    \"#d62728\",   # Support\n    \"#8c564b\",   # Operations\n    \"#bcbd22\",   # Planning\n    \"#7f7f7f\",   # System Guidance\n    \"#17becf\",   # Reporting\n    \"#2ca02c\",   # Project Progress\n    \"#1f77b4\"    # Finance\n]\n\n# Plot\nplt.figure(figsize=(8, 5))\nplt.barh(\n    df[\"Query Type\"],\n    df[\"Percentage\"],\n    color=colors\n)\n\nplt.xlabel(\"Percentage of Queries\")\nplt.title(\"AI Query Distribution by Business Dimension\")\n\n# Percentage labels\nfor index, value in enumerate(df[\"Percentage\"]):\n    plt.text(value + 0.5, index, f\"{value:.1f}%\", va=\"center\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:46:55.671171Z","iopub.execute_input":"2026-02-16T20:46:55.671433Z","iopub.status.idle":"2026-02-16T20:46:57.739483Z","shell.execute_reply.started":"2026-02-16T20:46:55.671407Z","shell.execute_reply":"2026-02-16T20:46:57.738114Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n### 5.4 Key Insight\n\nThe AI is primarily used to **analyze and interpret financial and project management information**, rather than to execute operational tasks or resolve technical issues.\n\nFinancial, project progress, and reporting-related queries account for the vast majority of interactions. This suggests that **users perceive the AI as an analytical support tool** rather than an operational assistant.\n\nLower percentages in operational and support-related queries may reflect either limited feature awareness or a natural usage pattern centered on high-level decision-making.\n\n### 5.5 Methodological Note\n\nThis classification is exploratory and heuristic-based, derived from keyword matching and manual review of representative samples.\n\nCategories are not mutually exclusive at the message level; instead, they provide **directional insight into dominant themes across interactions**.\n\nAt this stage, the classification is implemented for analytical exploration. However, its structure is intentionally designed to be replicable and can later be automated using a dedicated NLP model within the live dashboard environment.\n\n### 5.6 Notes on Potential Automation\n\nThe current topic classification is based on rule-based keyword matching, designed for exploratory and descriptive analysis.\n\nWhile this approach is sufficient to understand high-level usage patterns, it has limitations:\n- Queries may belong to more than one category\n- Keyword rules require manual maintenance\n- Contextual meaning is not fully captured\n\nIf this analysis were to evolve into a production monitoring system, a supervised text classification model could replace the heuristic rules to provide more consistent tagging.\n\nFor the scope of this project, the objective is to establish a defensible analytical framework and demonstrate how query behavior can be structured and interpreted.","metadata":{}},{"cell_type":"markdown","source":"## 6. Cross-Sectional Insights\n\nBased on exploratory and behavioral analysis, the following high-level insights were identified:\n\n1. The AI is primarily used as an **analytical assistant** rather than a search tool or operational interface.\n\n2. A large portion of user queries are **complex or multi-dimensional**, often combining financial, operational, and progress-related aspects.\n\n3. Friction appears to stem less from technical errors and more from **clarity, synthesis, and information prioritization.**\n\n4. Users actively explore project data, but first responses do not always fully resolve their intent.\n\n5. There is a clear opportunity to improve user experience through more structured summaries and clearer prioritization of key information.","metadata":{}},{"cell_type":"markdown","source":"## 7. Core KPIs\n\nThe following KPIs were defined to measure usage, quality, efficiency, and cost of the AI system.","metadata":{}},{"cell_type":"markdown","source":"### KPI 1 — Satisfactory Response Rate\n\n**Value:** 39%\n\n**Definition:**  \nPercentage of sessions resolved within 1 or 2 real queries, without explicit technical errors.\n\n**Interpretation:**  \nApproximately 4 out of 10 conversations are resolved clearly and efficiently in the first interaction cycle.","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 1\n\nThe following query was executed in BigQuery to calculate the Satisfactory Response Rate:","metadata":{}},{"cell_type":"markdown","source":"```sql\n    WITH base AS (\n  SELECT\n    UserId,\n    event_ts,\n    message,\n    Error,\n    LAG(event_ts) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS prev_ts\n  FROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_producto_vw`\n),\n\n-- Identify new sessions based on 10-minute inactivity threshold\nsessions AS (\n  SELECT\n    UserId,\n    event_ts,\n    message,\n    Error,\n    IF(\n      prev_ts IS NULL\n      OR TIMESTAMP_DIFF(event_ts, prev_ts, MINUTE) > 10,\n      1,\n      0\n    ) AS new_session_flag\n  FROM base\n),\n\n-- Assign session IDs per user\nsession_ids AS (\n  SELECT\n    UserId,\n    event_ts,\n    message,\n    Error,\n    SUM(new_session_flag) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS session_id\n  FROM sessions\n),\n\n-- Aggregate session-level metrics\nsession_metrics AS (\n  SELECT\n    UserId,\n    session_id,\n    COUNTIF(\n      LENGTH(message) >= 20\n      OR message LIKE '%?%'\n    ) AS real_queries,\n    MAX(CASE WHEN Error = 'ERROR' THEN 1 ELSE 0 END) AS has_error\n  FROM session_ids\n  GROUP BY UserId, session_id\n)\n\n-- Final KPI calculation\nSELECT\n  ROUND(\n    SAFE_DIVIDE(\n      COUNTIF(real_queries BETWEEN 1 AND 2 AND has_error = 0),\n      COUNT(*)\n    ),\n    4\n  ) AS satisfactory_response_rate\nFROM session_metrics;\n```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:43:28.095832Z","iopub.execute_input":"2026-02-16T19:43:28.096318Z","iopub.status.idle":"2026-02-16T19:43:28.107080Z","shell.execute_reply.started":"2026-02-16T19:43:28.096290Z","shell.execute_reply":"2026-02-16T19:43:28.105615Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# KPI Data\ndf = pd.DataFrame({\n    \"KPI\": [\"Satisfactory Response Rate\"],\n    \"Value\": [0.39]\n})\n\n# Plot\nplt.figure(figsize=(6, 2))\nplt.barh(\n    df[\"KPI\"],\n    df[\"Value\"],\n    color=\"#1f77b4\"\n)\n\nplt.xlim(0, 1)\nplt.title(\"Satisfactory Response Rate\", fontsize=12)\nplt.xlabel(\"Session Proportion\")\nplt.ylabel(\"\")\n\n# Value label\nplt.text(\n    df[\"Value\"][0] + 0.02,\n    0,\n    \"39%\",\n    va=\"center\",\n    fontsize=11\n)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:47:11.363484Z","iopub.execute_input":"2026-02-16T20:47:11.363889Z","iopub.status.idle":"2026-02-16T20:47:11.481308Z","shell.execute_reply.started":"2026-02-16T20:47:11.363854Z","shell.execute_reply":"2026-02-16T20:47:11.480284Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KPI 2 — Reformulation Rate\n\n**Value:** 70%\n\n**Definition:**\nPercentage of sessions where the user performs more than one real query.\n\nA session is considered reformulated if it contains more than one real query (real queries are defined as messages with ≥20 characters or containing a question mark).\n\n**Interpretation:**\nMost users need to insist, refine, or reformulate their request before obtaining a satisfactory answer.  \n\nThis suggests friction in clarity, response structure, or answer prioritization rather than purely technical failure.","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 2\n\nThe following query was executed in BigQuery to calculate the Reformulation Rate:","metadata":{}},{"cell_type":"markdown","source":"```sql\nWITH base AS (\n  SELECT\n    UserId,\n    event_ts,\n    message,\n    LENGTH(message) AS msg_length,\n    LAG(event_ts) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS prev_ts\n  FROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_producto_vw`\n),\n\n-- Filter trivial messages:\n-- Include only messages that:\n--   - have 20 or more characters\n--   - OR contain a question mark\nfiltered_base AS (\n  SELECT *\n  FROM base\n  WHERE msg_length >= 20\n     OR message LIKE '%?%'\n),\n\n-- Identify new sessions using a 10-minute inactivity threshold\nsessions AS (\n  SELECT\n    UserId,\n    event_ts,\n    IF(\n      prev_ts IS NULL\n      OR TIMESTAMP_DIFF(event_ts, prev_ts, MINUTE) > 10,\n      1,\n      0\n    ) AS new_session_flag\n  FROM filtered_base\n),\n\n-- Assign cumulative session IDs\nsession_ids AS (\n  SELECT\n    UserId,\n    event_ts,\n    SUM(new_session_flag) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS session_id\n  FROM sessions\n),\n\n-- Count number of real queries per session\nsession_counts AS (\n  SELECT\n    UserId,\n    session_id,\n    COUNT(*) AS queries_in_session\n  FROM session_ids\n  GROUP BY UserId, session_id\n)\n\n-- Final KPI calculation:\n-- Sessions with more than one real query divided by total sessions\nSELECT\n  COUNTIF(queries_in_session > 1) / COUNT(*) AS reformulation_rate\nFROM session_counts;\n```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:35:55.883310Z","iopub.status.idle":"2026-02-16T19:35:55.883747Z","shell.execute_reply.started":"2026-02-16T19:35:55.883571Z","shell.execute_reply":"2026-02-16T19:35:55.883587Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# KPI Data\ndf = pd.DataFrame({\n    \"KPI\": [\"Reformulated Sessions\"],\n    \"Value\": [0.70]\n})\n\n# Plot\nplt.figure(figsize=(6, 2))\nplt.barh(\n    df[\"KPI\"],\n    df[\"Value\"],\n    color=\"#ff7f0e\"  # subtle orange to differentiate from KPI 1\n)\n\nplt.xlim(0, 1)\nplt.title(\"Reformulation Rate\", fontsize=12)\nplt.xlabel(\"Session Proportion\")\nplt.ylabel(\"\")\n\n# Value label\nplt.text(\n    df[\"Value\"][0] + 0.02,\n    0,\n    \"70%\",\n    va=\"center\",\n    fontsize=11\n)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2026-02-16T20:47:15.362925Z","iopub.execute_input":"2026-02-16T20:47:15.363429Z","iopub.status.idle":"2026-02-16T20:47:15.470941Z","shell.execute_reply.started":"2026-02-16T20:47:15.363397Z","shell.execute_reply":"2026-02-16T20:47:15.469820Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KPI 3 — Average Queries per Session\n\n**Value**: 5.36 queries\n\n**Definition:**\nAverage number of real queries per session.\n\n**Interpretation:**\nConversations tend to involve multiple interactions, suggesting users refine, expand, or deepen their requests within the same session.","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 3\n\nThe following query was executed in BigQuery to calculate the average number of real queries per session:","metadata":{}},{"cell_type":"markdown","source":"```sql\n    WITH base AS (\n  SELECT\n    UserId,\n    event_ts,\n    message,\n    LENGTH(message) AS msg_length,\n    LAG(event_ts) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS prev_ts\n  FROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_producto_vw`\n),\n\n-- Keep only real queries\nfiltered_base AS (\n  SELECT *\n  FROM base\n  WHERE msg_length >= 20\n     OR message LIKE '%?%'\n),\n\n-- Identify session boundaries (10-minute rule)\nsessions AS (\n  SELECT\n    UserId,\n    event_ts,\n    IF(\n      prev_ts IS NULL\n      OR TIMESTAMP_DIFF(event_ts, prev_ts, MINUTE) > 10,\n      1,\n      0\n    ) AS new_session_flag\n  FROM filtered_base\n),\n\n-- Assign session IDs\nsession_ids AS (\n  SELECT\n    UserId,\n    event_ts,\n    SUM(new_session_flag) OVER (\n      PARTITION BY UserId\n      ORDER BY event_ts\n    ) AS session_id\n  FROM sessions\n),\n\n-- Count queries per session\nsession_counts AS (\n  SELECT\n    UserId,\n    session_id,\n    COUNT(*) AS queries_in_session\n  FROM session_ids\n  GROUP BY UserId, session_id\n)\n\nSELECT\n  AVG(queries_in_session) AS avg_queries_per_session\nFROM session_counts;\n    ```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:35:55.887733Z","iopub.status.idle":"2026-02-16T19:35:55.888257Z","shell.execute_reply.started":"2026-02-16T19:35:55.888006Z","shell.execute_reply":"2026-02-16T19:35:55.888028Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# KPI data\ndf = pd.DataFrame({\n    \"KPI\": [\"Average Queries per Session\"],\n    \"Value\": [5.36]\n})\n\n# Plot\nplt.figure(figsize=(4, 4))\nplt.bar(\n    df[\"KPI\"],\n    df[\"Value\"],\n    color=\"#7f7f7f\"\n)\n\nplt.title(\"Average Queries per Session\", fontsize=12)\nplt.ylabel(\"Number of Queries\")\nplt.ylim(0, 6)\n\n# Value label\nplt.text(\n    0,\n    df[\"Value\"][0] + 0.15,\n    \"5.36\",\n    ha=\"center\",\n    fontsize=11\n)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:47:18.337118Z","iopub.execute_input":"2026-02-16T20:47:18.338218Z","iopub.status.idle":"2026-02-16T20:47:18.468274Z","shell.execute_reply.started":"2026-02-16T20:47:18.338179Z","shell.execute_reply":"2026-02-16T20:47:18.466930Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KPI 4 — Explicit Error Rate\n\n**Value**: 0.9%\n\n**Definition**:\nPercentage of interactions where at least one explicit technical error was recorded by the system (Error = 'ERROR').\n\n**Interpretation**:\nThe explicit technical error rate is low (~0.9%), indicating system stability during the analyzed period. This metric serves as a technical reliability baseline for future monitoring.","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 4\n\nThe following query was executed in BigQuery to calculate the Explicit Error Rate:","metadata":{}},{"cell_type":"markdown","source":"```sql\nSELECT\n  COUNTIF(TRIM(UPPER(Error)) = 'ERROR') / COUNT(*) AS explicit_error_rate\nFROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_producto_vw`;\n```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:35:55.895870Z","iopub.status.idle":"2026-02-16T19:35:55.896459Z","shell.execute_reply.started":"2026-02-16T19:35:55.896189Z","shell.execute_reply":"2026-02-16T19:35:55.896212Z"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# KPI value (replace if recalculated)\nerror_rate = 0.009  # 0.9%\n\nplt.figure(figsize=(4, 2))\n\nplt.text(\n    0.5, 0.6,\n    f\"{error_rate*100:.1f}%\",\n    ha=\"center\",\n    va=\"center\",\n    fontsize=32,\n    color=\"#d62728\"  # soft red for errors\n)\n\nplt.text(\n    0.5, 0.25,\n    \"Explicit Error Rate\",\n    ha=\"center\",\n    va=\"center\",\n    fontsize=12\n)\n\nplt.axis(\"off\")\nplt.title(\"KPI 4 — Explicit Error Rate\", fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:47:25.361456Z","iopub.execute_input":"2026-02-16T20:47:25.361923Z","iopub.status.idle":"2026-02-16T20:47:25.444495Z","shell.execute_reply.started":"2026-02-16T20:47:25.361881Z","shell.execute_reply":"2026-02-16T20:47:25.443084Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KPI 5 — AI Response Time Performance\n\n**Value:**\n\n- Average TTFT: ~0.77 seconds\n- Average Total Duration: ~6.96 seconds\n    \n(Initial sample — exploratory baseline)\n\n\n**Definition:**\n\nThis KPI measures how long the AI takes:\n- To start responding (TTFT – Time To First Token)\n- To complete the full response (Total Duration)\n\nMetrics are calculated in milliseconds and converted to seconds for interpretation.\n\n**Interpretation:**\n\n- The AI starts responding in under 1 second, which supports a strong perception of responsiveness.\n- The total response duration is higher, which is expected for analytical and multi-step answers.\n- This KPI establishes a performance baseline for future monitoring as usage scales.\n\n⸻\n\n***Methodological Note:***\n\nValues represent an initial usage sample and should be interpreted as a performance baseline, not as a statistically conclusive benchmark.","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 5\n\nThe following query was executed in BigQuery to calculate the AI Response Time Performance:","metadata":{}},{"cell_type":"markdown","source":"```sql\nSELECT\n  COUNT(*) AS total_queries,\n  ROUND(AVG(ttft), 2) AS avg_ttft_ms,\n  ROUND(AVG(duration_ms), 2) AS avg_duration_ms,\n  ROUND(APPROX_QUANTILES(ttft, 100)[OFFSET(50)], 2) AS median_ttft_ms,\n  ROUND(APPROX_QUANTILES(duration_ms, 100)[OFFSET(50)], 2) AS median_duration_ms\nFROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_tiempos_tokens_vw`;\n```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:35:55.900730Z","iopub.status.idle":"2026-02-16T19:35:55.901279Z","shell.execute_reply.started":"2026-02-16T19:35:55.901009Z","shell.execute_reply":"2026-02-16T19:35:55.901030Z"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Baseline values converted to seconds\nlabels = ['TTFT (Response Start)', 'Total Duration']\nvalues = [0.77, 6.96]  # seconds\n\nplt.figure(figsize=(5, 3))\nbars = plt.bar(labels, values, color=['#1f77b4', '#ff7f0e'])\n\nplt.ylabel('Seconds')\nplt.title('Average AI Response Time')\n\n# Add value labels above bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2,\n        height,\n        f'{height:.2f}s',\n        ha='center',\n        va='bottom'\n    )\n\nplt.ylim(0, max(values) * 1.3)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:47:28.678838Z","iopub.execute_input":"2026-02-16T20:47:28.679985Z","iopub.status.idle":"2026-02-16T20:47:28.889804Z","shell.execute_reply.started":"2026-02-16T20:47:28.679944Z","shell.execute_reply":"2026-02-16T20:47:28.888829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### KPI 6 — Cost per Query\n\n**Value:** \nUSD 0.1924 per query\n\n**Definition:**\n\nAverage estimated cost in USD per AI query, calculated based on input tokens (prompt) and output tokens (response), using the pricing model applied at the time of analysis.\n\n**Interpretation:**\n\nThe average cost per query reflects relatively long and analytical responses.\nAt this stage, the metric serves as a financial baseline to monitor efficiency, scalability, and optimization opportunities as usage grows.\n\n⸻\n\n***Methodological Note:***\n\nValues represent an initial usage sample and should be interpreted as a cost baseline, not as a scaled production benchmark.\n\n","metadata":{}},{"cell_type":"markdown","source":"#### SQL Used to Calculate KPI 6\n\nThe following query was executed in BigQuery to estimate the average and total cost based on token consumption:","metadata":{}},{"cell_type":"markdown","source":"```sql\nSELECT\n  COUNT(*) AS total_consultas,\n  ROUND(\n    AVG(\n      (prompt_token_count / 1000000.0 * 0.50) +\n      (candidates_token_count / 1000000.0 * 3.00)\n    ),\n    6\n  ) AS avg_cost_per_query_usd,\n  ROUND(\n    SUM(\n      (prompt_token_count / 1000000.0 * 0.50) +\n      (candidates_token_count / 1000000.0 * 3.00)\n    ),\n    6\n  ) AS total_cost_usd\nFROM `conductive-bank-469015-r4.esfera_IA.logs_ai_esfera_tiempos_tokens_vw`;\n```","metadata":{"execution":{"iopub.status.busy":"2026-02-16T19:35:55.907656Z","iopub.status.idle":"2026-02-16T19:35:55.908742Z","shell.execute_reply.started":"2026-02-16T19:35:55.908431Z","shell.execute_reply":"2026-02-16T19:35:55.908458Z"}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# KPI value \navg_cost = 0.192402  # USD per query\n\nplt.figure(figsize=(4, 2))\n\nplt.text(\n    0.5, 0.6,\n    f\"${avg_cost:.4f}\",\n    ha=\"center\",\n    va=\"center\",\n    fontsize=32,\n    color=\"#9467bd\"\n)\n\nplt.text(\n    0.5, 0.25,\n    \"Average cost per query\",\n    ha=\"center\",\n    va=\"center\",\n    fontsize=12\n)\n\nplt.axis(\"off\")\nplt.title(\"KPI 6 — Cost per Query (USD)\", fontsize=12)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T20:47:32.501443Z","iopub.execute_input":"2026-02-16T20:47:32.502536Z","iopub.status.idle":"2026-02-16T20:47:32.576101Z","shell.execute_reply.started":"2026-02-16T20:47:32.502497Z","shell.execute_reply":"2026-02-16T20:47:32.575042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Strategic Insights\n\nBased on the exploratory analysis and KPI results, several strategic conclusions emerge:\n\n1.\t**The AI is primarily used as an analytical assistant**, not as an operational tool.\nMost queries relate to financial, project progress, and reporting topics.\n2. **Technical stability is strong (low explicit error rate)**, but satisfaction remains moderate.\nThis suggests that friction is more related to response clarity and synthesis than system reliability.\n3. **High reformulation rate (70%) indicates iteration behavior**, meaning users often refine or clarify their requests.\n4. **Average queries per session (5.36) reflect complex interactions**, not one-shot questions.\n5. **Cost and response time establish an operational baseline** for future monitoring and scaling decisions.","metadata":{}},{"cell_type":"markdown","source":"## 9. Monitoring & Dashboard Integration\n\nThe defined KPIs were operationalized into interactive dashboards built in Tableau.\n\nTwo complementary dashboard layers were designed:\n\n### Dashboard 1 – System Status & Usage\nProvides a consolidated executive view including:\n- Usage distribution\n- Satisfactory response rate\n- Reformulation rate\n- Explicit error rate\n- Cost per query\n\nDesigned for product, leadership, and operational monitoring.\n\n### Dashboard 2 – Technical Performance Exploration\nFocused on:\n- TTFT vs total response duration\n- Temporal evolution structure\n- Baseline performance tracking\n\nThis layer supports longitudinal monitoring and performance scalability as usage grows.\n\nTogether, these dashboards translate analytical definitions into continuous monitoring infrastructure.","metadata":{}},{"cell_type":"markdown","source":"## 10. Conclusion\n\nThis project transforms raw conversational system logs into a structured analytical framework capable of measuring:\n\n- Usage patterns\n- Interaction quality\n- Technical stability\n- Operational cost\n\nThe system is technically stable and actively used for analytical purposes. \nCurrent improvement opportunities are concentrated in response clarity, synthesis quality, and user guidance rather than infrastructure reliability.\n\nThe defined KPIs and monitoring structure provide a scalable foundation for continuous evaluation as adoption increases.","metadata":{}}]}